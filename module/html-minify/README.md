# 压缩快照体积

爬虫运行中可以给网页源码储存下来，用来还原抓取时页面的模样，这称为快照。

通过爬虫（浏览器）直接生成的快照，体积往往比较大，批量储存需要一定成本，一般会先压缩再储存。总的来说，有三种方案：

1. 将页面保存为图片
2. 非语义压缩
3. 语义压缩

从感觉上来说，网页白底黑字，顶多加几张小图片，用 PNG 图片储存可以剩下许多空间，非常合适。不过经实际测试才发现，由于截图的分辨率比较大（1920 \* 1080+），就算应用压缩率极高的算法，生成的图片体积也很大（好比未压缩的快照）的图片。此外，使用截图保存会忽略很多其他的信息，如鼠标与页面图片、超链接等交互。

非语义压缩是指在不处理源码原有信息的情况下进行压缩。去除脚本、去除空标签、去除注释是非语义化压缩的三个大头，一般会借助正则去处理。这种方法速度比较快，时间复杂度可以认为是 $O(n)$。

语义化压缩则需要回到源码，通过将源码转换为 DOM/CSSOM。分析后，可以进行去除死代码、标签压缩等操作。此方法压缩率较高，但是需要占用较长的 CPU 时间。

## 语义化压缩

为什么不直接使用现成的 CSS Tree Shake 方案，如 PurifyCSS？

因为他们对代码容错的支持不友好。
